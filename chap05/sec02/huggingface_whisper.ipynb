{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (24.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.0.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Downloading pip-25.0.1-py3-none-any.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.8/1.8 MB 12.6 MB/s eta 0:00:00\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 24.3.1\n",
      "    Uninstalling pip-24.3.1:\n",
      "      Successfully uninstalled pip-24.3.1\n",
      "Successfully installed pip-25.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting transformers\n",
      "  Using cached transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting accelerate\n",
      "  Using cached accelerate-1.3.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting datasets[audio]\n",
      "  Using cached datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Using cached filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.24.0 (from transformers)\n",
      "  Downloading huggingface_hub-0.28.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from transformers) (2.2.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from transformers)\n",
      "  Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: requests in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.1 (from transformers)\n",
      "  Using cached safetensors-0.5.2-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from datasets[audio]) (19.0.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets[audio])\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from datasets[audio]) (2.2.3)\n",
      "Collecting xxhash (from datasets[audio])\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets[audio])\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets[audio])\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets[audio])\n",
      "  Downloading aiohttp-3.11.12-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting soundfile>=0.12.1 (from datasets[audio])\n",
      "  Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting librosa (from datasets[audio])\n",
      "  Using cached librosa-0.10.2.post1-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting soxr>=0.4.0 (from datasets[audio])\n",
      "  Using cached soxr-0.5.0.post1-cp312-abi3-win_amd64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: psutil in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from accelerate) (6.1.1)\n",
      "Collecting torch>=2.0.0 (from accelerate)\n",
      "  Using cached torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets[audio])\n",
      "  Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets[audio])\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from aiohttp->datasets[audio]) (25.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets[audio])\n",
      "  Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets[audio])\n",
      "  Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets[audio])\n",
      "  Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl.metadata (9.5 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets[audio])\n",
      "  Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Collecting cffi>=1.0 (from soundfile>=0.12.1->datasets[audio])\n",
      "  Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting networkx (from torch>=2.0.0->accelerate)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
      "Collecting setuptools (from torch>=2.0.0->accelerate)\n",
      "  Using cached setuptools-75.8.0-py3-none-any.whl.metadata (6.7 kB)\n",
      "Collecting sympy==1.13.1 (from torch>=2.0.0->accelerate)\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch>=2.0.0->accelerate)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: colorama in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Collecting audioread>=2.1.9 (from librosa->datasets[audio])\n",
      "  Using cached audioread-3.0.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting scipy>=1.2.0 (from librosa->datasets[audio])\n",
      "  Using cached scipy-1.15.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting scikit-learn>=0.20.0 (from librosa->datasets[audio])\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting joblib>=0.14 (from librosa->datasets[audio])\n",
      "  Using cached joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from librosa->datasets[audio]) (5.1.1)\n",
      "Collecting numba>=0.51.0 (from librosa->datasets[audio])\n",
      "  Using cached numba-0.61.0-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting pooch>=1.1 (from librosa->datasets[audio])\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting lazy-loader>=0.1 (from librosa->datasets[audio])\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa->datasets[audio])\n",
      "  Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from pandas->datasets[audio]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from pandas->datasets[audio]) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from pandas->datasets[audio]) (2025.1)\n",
      "Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->datasets[audio])\n",
      "  Using cached pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba>=0.51.0->librosa->datasets[audio])\n",
      "  Using cached llvmlite-0.44.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting numpy>=1.17 (from transformers)\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from pooch>=1.1->librosa->datasets[audio]) (4.3.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets[audio]) (1.17.0)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=0.20.0->librosa->datasets[audio])\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\github\\gpt_agent_2025_easyspub\\venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Using cached transformers-4.48.3-py3-none-any.whl (9.7 MB)\n",
      "Using cached accelerate-1.3.0-py3-none-any.whl (336 kB)\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "Downloading aiohttp-3.11.12-cp312-cp312-win_amd64.whl (437 kB)\n",
      "Downloading huggingface_hub-0.28.1-py3-none-any.whl (464 kB)\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Using cached PyYAML-6.0.2-cp312-cp312-win_amd64.whl (156 kB)\n",
      "Using cached regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "Using cached safetensors-0.5.2-cp38-abi3-win_amd64.whl (303 kB)\n",
      "Downloading soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 24.4 MB/s eta 0:00:00\n",
      "Using cached soxr-0.5.0.post1-cp312-abi3-win_amd64.whl (164 kB)\n",
      "Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "Using cached torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Using cached datasets-3.2.0-py3-none-any.whl (480 kB)\n",
      "Using cached filelock-3.17.0-py3-none-any.whl (16 kB)\n",
      "Using cached librosa-0.10.2.post1-py3-none-any.whl (260 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.6-py3-none-any.whl (14 kB)\n",
      "Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached audioread-3.0.1-py3-none-any.whl (23 kB)\n",
      "Using cached cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Using cached frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "Using cached joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Using cached msgpack-1.1.0-cp312-cp312-win_amd64.whl (75 kB)\n",
      "Using cached multidict-6.1.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Using cached numba-0.61.0-cp312-cp312-win_amd64.whl (2.8 MB)\n",
      "Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 5.5/12.6 MB 25.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.4/12.6 MB 23.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 10.7/12.6 MB 17.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 17.9 MB/s eta 0:00:00\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached propcache-0.2.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "Using cached scipy-1.15.1-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "Using cached yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-75.8.0-py3-none-any.whl (1.2 MB)\n",
      "Using cached llvmlite-0.44.0-cp312-cp312-win_amd64.whl (30.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: mpmath, xxhash, threadpoolctl, sympy, setuptools, safetensors, regex, pyyaml, pycparser, propcache, numpy, networkx, multidict, msgpack, llvmlite, lazy-loader, joblib, fsspec, frozenlist, filelock, dill, audioread, aiohappyeyeballs, yarl, torch, soxr, scipy, pooch, numba, multiprocess, huggingface-hub, cffi, aiosignal, tokenizers, soundfile, scikit-learn, aiohttp, accelerate, transformers, librosa, datasets\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.2\n",
      "    Uninstalling numpy-2.2.2:\n",
      "      Successfully uninstalled numpy-2.2.2\n",
      "Successfully installed accelerate-1.3.0 aiohappyeyeballs-2.4.6 aiohttp-3.11.12 aiosignal-1.3.2 audioread-3.0.1 cffi-1.17.1 datasets-3.2.0 dill-0.3.8 filelock-3.17.0 frozenlist-1.5.0 fsspec-2024.9.0 huggingface-hub-0.28.1 joblib-1.4.2 lazy-loader-0.4 librosa-0.10.2.post1 llvmlite-0.44.0 mpmath-1.3.0 msgpack-1.1.0 multidict-6.1.0 multiprocess-0.70.16 networkx-3.4.2 numba-0.61.0 numpy-2.1.3 pooch-1.8.2 propcache-0.2.1 pycparser-2.22 pyyaml-6.0.2 regex-2024.11.6 safetensors-0.5.2 scikit-learn-1.6.1 scipy-1.15.1 setuptools-75.8.0 soundfile-0.13.1 soxr-0.5.0.post1 sympy-1.13.1 threadpoolctl-3.5.0 tokenizers-0.21.0 torch-2.6.0 transformers-4.48.3 xxhash-3.5.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip \n",
    "%pip install --upgrade transformers datasets[audio] accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"C:\\github\\gpt_agent_2025_easyspub\\ffmpeg-2025-02-10-full_build\\bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "c:\\github\\gpt_agent_2025_easyspub\\venv\\Lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:573: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ' 안녕하세요. 이 강의는 GPT API로 챗봇 만들기 라는 내용을 다루는 강의입니다. GPT API에 대해서 생소하신 분들도 있을텐데 우리가 잘 알고 있는 ChatGPT, ChatGPT 기능을 이용해서 우리가 원하는 프로그램을 어떻게 만드는지에 대해서 이야기할 거예요. 그래서 이런 강의들이 사실 많이 있습니다. 그래서 여러 가지들이 있는데 이 강의 특징이라고 한다면 GPT로 명확한 미션을 달성하는 챕터 프로그램을 만드는게 사실 쉽지는 않은데 이걸 어떻게 해서 구현을 하는지 그리고 그게 왜 필요한지에 대해서 좀 이야기를 할 거고요. 그 예제로 예제는 여러가지가 될 수 있는데 여기서 예제로 하는 것은 음악 플레이리스트 동영상을 자동으로 대화를 통해서 생성하는 프로그램을 만드는 것을 다루려고 합니다. 그래서 프로그램이 실행되는 모습을 한번 보여드릴게요. 우리가 만들 프로그램은 이런 식으로 이제 나타나게 되고', 'chunks': [{'timestamp': (0.0, 6.3), 'text': ' 안녕하세요. 이 강의는 GPT API로 챗봇 만들기 라는 내용을 다루는 강의입니다.'}, {'timestamp': (7.18, 10.0), 'text': ' GPT API에 대해서 생소하신 분들도 있을텐데'}, {'timestamp': (11.0, 17.0), 'text': ' 우리가 잘 알고 있는 ChatGPT, ChatGPT 기능을 이용해서'}, {'timestamp': (17.0, 21.0), 'text': ' 우리가 원하는 프로그램을 어떻게 만드는지에 대해서 이야기할 거예요.'}, {'timestamp': (21.0, 24.0), 'text': ' 그래서 이런 강의들이 사실 많이 있습니다.'}, {'timestamp': (24.0, 27.48), 'text': ' 그래서 여러 가지들이 있는데 이 강의 특징이라고 한다면'}, {'timestamp': (27.48, 29.58), 'text': ' GPT로 명확한 미션을 달성하는'}, {'timestamp': (29.58, 31.66), 'text': ' 챕터 프로그램을 만드는게 사실'}, {'timestamp': (31.66, 34.32), 'text': ' 쉽지는 않은데 이걸 어떻게 해서'}, {'timestamp': (34.32, 36.4), 'text': ' 구현을 하는지 그리고 그게 왜 필요한지에 대해서'}, {'timestamp': (36.4, 37.36), 'text': ' 좀 이야기를 할 거고요.'}, {'timestamp': (38.0, 40.0), 'text': ' 그 예제로 예제는 여러가지가 될 수 있는데'}, {'timestamp': (40.0, 42.0), 'text': ' 여기서 예제로 하는 것은'}, {'timestamp': (42.0, 44.2), 'text': ' 음악 플레이리스트 동영상을'}, {'timestamp': (44.2, 47.1), 'text': ' 자동으로 대화를 통해서 생성하는 프로그램을 만드는 것을'}, {'timestamp': (47.1, 48.46), 'text': ' 다루려고 합니다.'}, {'timestamp': (49.84, 51.96), 'text': ' 그래서 프로그램이 실행되는 모습을 한번 보여드릴게요.'}, {'timestamp': (52.84, 58.0), 'text': ' 우리가 만들 프로그램은 이런 식으로 이제 나타나게 되고'}]}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "# from datasets import load_dataset\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    return_timestamps=True,   # 청크별로 타임스탬프 반환\n",
    "    chunk_length_s=10,  # 입력 오디오 10초씩 나누기r\n",
    "    stride_length_s=2,  # 2초씩 겹치도록 청크 나누기\n",
    ") \n",
    "\n",
    "# dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "# sample = dataset[0][\"audio\"]\n",
    "sample = \"../audio/lsy_audio_2023_58s.mp3\"\n",
    "\n",
    "result = pipe(sample)\n",
    "# print(result[\"text\"])\n",
    "\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>6.30</td>\n",
       "      <td>안녕하세요. 이 강의는 GPT API로 챗봇 만들기 라는 내용을 다루는 강의입니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.18</td>\n",
       "      <td>10.00</td>\n",
       "      <td>GPT API에 대해서 생소하신 분들도 있을텐데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.00</td>\n",
       "      <td>17.00</td>\n",
       "      <td>우리가 잘 알고 있는 ChatGPT, ChatGPT 기능을 이용해서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.00</td>\n",
       "      <td>21.00</td>\n",
       "      <td>우리가 원하는 프로그램을 어떻게 만드는지에 대해서 이야기할 거예요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21.00</td>\n",
       "      <td>24.00</td>\n",
       "      <td>그래서 이런 강의들이 사실 많이 있습니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>24.00</td>\n",
       "      <td>27.48</td>\n",
       "      <td>그래서 여러 가지들이 있는데 이 강의 특징이라고 한다면</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>27.48</td>\n",
       "      <td>29.58</td>\n",
       "      <td>GPT로 명확한 미션을 달성하는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29.58</td>\n",
       "      <td>31.66</td>\n",
       "      <td>챕터 프로그램을 만드는게 사실</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>31.66</td>\n",
       "      <td>34.32</td>\n",
       "      <td>쉽지는 않은데 이걸 어떻게 해서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>34.32</td>\n",
       "      <td>36.40</td>\n",
       "      <td>구현을 하는지 그리고 그게 왜 필요한지에 대해서</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36.40</td>\n",
       "      <td>37.36</td>\n",
       "      <td>좀 이야기를 할 거고요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>38.00</td>\n",
       "      <td>40.00</td>\n",
       "      <td>그 예제로 예제는 여러가지가 될 수 있는데</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>40.00</td>\n",
       "      <td>42.00</td>\n",
       "      <td>여기서 예제로 하는 것은</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>42.00</td>\n",
       "      <td>44.20</td>\n",
       "      <td>음악 플레이리스트 동영상을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>44.20</td>\n",
       "      <td>47.10</td>\n",
       "      <td>자동으로 대화를 통해서 생성하는 프로그램을 만드는 것을</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>47.10</td>\n",
       "      <td>48.46</td>\n",
       "      <td>다루려고 합니다.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>49.84</td>\n",
       "      <td>51.96</td>\n",
       "      <td>그래서 프로그램이 실행되는 모습을 한번 보여드릴게요.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>52.84</td>\n",
       "      <td>58.00</td>\n",
       "      <td>우리가 만들 프로그램은 이런 식으로 이제 나타나게 되고</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    start    end                                             text\n",
       "0    0.00   6.30   안녕하세요. 이 강의는 GPT API로 챗봇 만들기 라는 내용을 다루는 강의입니다.\n",
       "1    7.18  10.00                       GPT API에 대해서 생소하신 분들도 있을텐데\n",
       "2   11.00  17.00            우리가 잘 알고 있는 ChatGPT, ChatGPT 기능을 이용해서\n",
       "3   17.00  21.00            우리가 원하는 프로그램을 어떻게 만드는지에 대해서 이야기할 거예요.\n",
       "4   21.00  24.00                          그래서 이런 강의들이 사실 많이 있습니다.\n",
       "5   24.00  27.48                   그래서 여러 가지들이 있는데 이 강의 특징이라고 한다면\n",
       "6   27.48  29.58                                GPT로 명확한 미션을 달성하는\n",
       "7   29.58  31.66                                 챕터 프로그램을 만드는게 사실\n",
       "8   31.66  34.32                                쉽지는 않은데 이걸 어떻게 해서\n",
       "9   34.32  36.40                       구현을 하는지 그리고 그게 왜 필요한지에 대해서\n",
       "10  36.40  37.36                                    좀 이야기를 할 거고요.\n",
       "11  38.00  40.00                          그 예제로 예제는 여러가지가 될 수 있는데\n",
       "12  40.00  42.00                                    여기서 예제로 하는 것은\n",
       "13  42.00  44.20                                   음악 플레이리스트 동영상을\n",
       "14  44.20  47.10                   자동으로 대화를 통해서 생성하는 프로그램을 만드는 것을\n",
       "15  47.10  48.46                                        다루려고 합니다.\n",
       "16  49.84  51.96                    그래서 프로그램이 실행되는 모습을 한번 보여드릴게요.\n",
       "17  52.84  58.00                   우리가 만들 프로그램은 이런 식으로 이제 나타나게 되고"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# chunks를 CSV 파일로 저장\n",
    "start_end_text = []\n",
    "\n",
    "for chunk in result[\"chunks\"]:\n",
    "    start = chunk[\"timestamp\"][0]\n",
    "    end = chunk[\"timestamp\"][1]\n",
    "    text = chunk[\"text\"]\n",
    "    start_end_text.append([start, end, text])\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(start_end_text, columns=[\"start\", \"end\", \"text\"])\n",
    "df.to_csv(\"lsy_audio_2023_58.csv\", index=False, sep=\"|\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
